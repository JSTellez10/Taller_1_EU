bedrooms + bathrooms + log_surface + log_dom |
UPLCODIGO + tipo + tri_anio,
data = df, cluster = ~ UPLCODIGO)
list("(1)" = m1, "(2)" = m2, "(3)" = m3, "(4)" = m4, "(5)" = m5)
}
# Renombrado
rename_fun <- function(s) {
s %>%
str_replace("^A_parque$",        "Acceso a parques (A\u1D62)") %>%
str_replace("^bedrooms$",        "Dormitorios") %>%
str_replace("^bathrooms$",       "Ba\u00F1os") %>%
str_replace("^log_surface$",     "log(Superficie)") %>%
str_replace("^log_dom$",         "log(1 + d\u00EDas en mercado)") %>%
str_replace("^estrato",          "Estrato ") %>%
str_replace("^A_parque:estrato", "A\u1D62 \u00D7 Estrato ") %>%
str_replace("^A_parque:",        "A\u1D62 \u00D7 ")             # por si hay otras interacciones
}
# GOF a mostrar
gmap <- data.frame(
raw   = c("r.squared", "nobs", "fixef"),
clean = c("R\u00B2", "N", "FE incluidas"),
fmt   = c(2, 0, 0)
)
# Función que arma y guarda la tabla por operación
make_table <- function(op_sel, file_png) {
mods <- run_models_op(op_sel)  # usa tu función existente
tbl <- modelsummary::msummary(
mods,
output      = "gt",
coef_rename = rename_fun,
gof_map     = gmap,
stars       = c('*' = .1, '**' = .05, '***' = .01),
add_rows    = tibble::tibble(
term = "Errores est\u00E1ndar",
`(1)` = "Cluster: UPLCODIGO",
`(2)` = "Cluster: UPLCODIGO",
`(3)` = "Cluster: UPLCODIGO",
`(4)` = "Cluster: UPLCODIGO",
`(5)` = "Cluster: UPLCODIGO"
),
title = paste0("Operaci\u00F3n: ", op_sel,
" \u2014 log(Precio) ~ A_parque (Especificaciones (1)\u2013(5))")
) %>%
gt::tab_options(table.font.size = "small") %>%
gt::tab_source_note(
md("**Notas:** (4) incluye FE de UPLCODIGO y tipo; (5) agrega FE de trimestre-a\u00F1o (tri_anio).")
)
gt::gtsave(tbl, filename = file.path(views, file_png), zoom = 1)
}
# Vuelve a ejecutar y exportar
make_table("Venta",    "reg_parques_venta.png")
make_table("Alquiler", "reg_parques_alquiler.png")
# VARIANTES POR OPERACIÓN Y TABLAS: DIFERENCIAS vs CONLEY------
# 0) Preparación mínima: asegurar lon/lat y construir df "plano"
if (!("lon" %in% names(housing_data_sf))) {
coords_4326 <- sf::st_coordinates(housing_data_sf)
housing_data_sf <- housing_data_sf %>%
dplyr::mutate(lon = coords_4326[,1], lat = coords_4326[,2])
}
df <- housing_data_sf %>%
sf::st_drop_geometry() %>%
dplyr::filter(
is.finite(log_price),
is.finite(A_parque),
!is.na(estrato), !is.na(UPLCODIGO),
!is.na(tipo), !is.na(tri_anio),
!is.na(operation)
) %>%
dplyr::mutate(.row_id = dplyr::row_number())
# 1) Helpers: emparejamiento NN y construcción de diferencias
mk_pairs_nn <- function(dd){
# Devuelve SIEMPRE un data.frame con índices globales (.row_id)
if (nrow(dd) < 2L) {
return(tibble::tibble(i_row = integer(0), j_row = integer(0)))
}
dd_sf <- sf::st_as_sf(dd, coords = c("lon","lat"), crs = 4326) |>
sf::st_transform(3116)
XY   <- sf::st_coordinates(dd_sf)
nn   <- RANN::nn2(data = XY, query = XY, k = 2)   # vecino ≠ sí mismo
j_id <- nn$nn.idx[, 2]
i_ix <- seq_len(nrow(dd))
keep <- which(i_ix < j_id)                        # evitar duplicados i<j
tibble::tibble(
i_row = dd$.row_id[i_ix[keep]],
j_row = dd$.row_id[j_id[keep]]
)
}
build_diff <- function(base, pairs){
if (is.null(pairs) || nrow(pairs) == 0L) return(NULL)
i <- pairs$i_row; j <- pairs$j_row
d <- function(v) base[[v]][i] - base[[v]][j]
out <- tibble::tibble(
d_log_price   = d("log_price"),
d_A_parque    = d("A_parque"),
d_bedrooms    = d("bedrooms"),
d_bathrooms   = d("bathrooms"),
d_log_surface = d("log_surface"),
d_log_dom     = d("log_dom"),
estrato_i     = as.factor(base$estrato[i]),
UPL_i         = base$UPLCODIGO[i]
) |>
dplyr::filter(dplyr::if_all(dplyr::where(is.numeric), is.finite))
if (nrow(out) == 0L) return(NULL)
out
}
# 2) Variantes por operación (Venta / Alquiler)
# Especificación con FE (para Conley)
f_fe <- log_price ~ A_parque * estrato +
bedrooms + bathrooms + log_surface + log_dom | UPLCODIGO + tipo + tri_anio
# VCOV Conley (ajusta cutoff si lo deseas)
vc_conley <- fixest::vcov_conley(lat = ~ lat, lon = ~ lon, cutoff = 50)
# Variante: FE + Conley (devuelve 1 modelo para una operación)
run_conley <- function(op_val){
d_op <- df %>% dplyr::filter(operation == op_val)
mod  <- fixest::feols(f_fe, data = d_op, vcov = vc_conley)
attr(mod, "se.type") <- "Conley"
mod
}
# Variante: Diferencias espaciales (NN dentro de UPL×tipo×tri_anio)
run_diff <- function(op_val){
d_op <- df %>% dplyr::filter(operation == op_val)
pairs_df <- d_op %>%
dplyr::group_by(UPLCODIGO, tipo, tri_anio) %>%
dplyr::group_modify(~ mk_pairs_nn(.x)) %>%
dplyr::ungroup()
df_diff <- build_diff(d_op, pairs_df)
if (is.null(df_diff)) {
# modelo "placeholder" si no hay pares suficientes
mod <- stats::lm(d_log_price ~ 1, data = data.frame(d_log_price = NA_real_))
attr(mod, "se.type") <- "HC (dif.)"
attr(mod, "note")    <- "Sin pares NN suficientes para diferencias espaciales"
return(mod)
}
mod <- stats::lm(
d_log_price ~ d_A_parque * estrato_i + d_bedrooms + d_bathrooms + d_log_surface + d_log_dom,
data = df_diff
)
attr(mod, "se.type") <- "HC (dif.)"
mod
}
# 3) Correr los 4 modelos (2 variantes × 2 operaciones)
m_diff_venta    <- run_diff("Venta")
m_diff_alquiler <- run_diff("Alquiler")
m_conley_venta    <- run_conley("Venta")
m_conley_alquiler <- run_conley("Alquiler")
# 4) Tablas separadas por variante (comparan Alquiler vs Venta)
# Renombrado amigable para ambas tablas
rename_fun_all <- function(s){
s %>%
stringr::str_replace("^d_A_parque$",          "\u0394 Acceso a parques (A\u1D62)") %>%
stringr::str_replace("^A_parque$",            "Acceso a parques (A\u1D62)") %>%
stringr::str_replace("^d_bedrooms$",          "\u0394 Dormitorios") %>%
stringr::str_replace("^d_bathrooms$",         "\u0394 Ba\u00F1os") %>%
stringr::str_replace("^d_log_surface$",       "\u0394 log(Superficie)") %>%
stringr::str_replace("^d_log_dom$",           "\u0394 log(1 + d\u00EDas en mercado)") %>%
stringr::str_replace("^bedrooms$",            "Dormitorios") %>%
stringr::str_replace("^bathrooms$",           "Ba\u00F1os") %>%
stringr::str_replace("^log_surface$",         "log(Superficie)") %>%
stringr::str_replace("^log_dom$",             "log(1 + d\u00EDas en mercado)") %>%
stringr::str_replace("^estrato",              "Estrato ") %>%
stringr::str_replace("^d_A_parque:estrato_i", "A\u1D62 \u00D7 Estrato (dif)")
}
gmap_common <- data.frame(
raw   = c("r.squared", "nobs", "fixef", "se.type"),
clean = c("R\u00B2", "N", "FE incluidas", "Errores est\u00E1ndar"),
fmt   = c(2, 0, 0, 0)
)
# TABLA 1: DIFERENCIAS ESPACIALES (Alquiler vs Venta) ----------
mods_diff <- list(
"Venta - Dif. espaciales"    = m_diff_venta,
"Alquiler - Dif. espaciales" = m_diff_alquiler
)
# Si se perdió el atributo de SE, lo restauramos de forma segura
if (is.null(attr(mods_diff[[1]], "se.type"))) attr(mods_diff[[1]], "se.type") <- "HC (dif.)"
if (is.null(attr(mods_diff[[2]], "se.type"))) attr(mods_diff[[2]], "se.type") <- "HC (dif.)"
tbl_diff <- modelsummary::msummary(
mods_diff,
output      = "gt",
coef_rename = rename_fun_all,
gof_map     = gmap_common,
stars       = c('*' = .1, '**' = .05, '***' = .01),
title       = "Diferencias espaciales (NN dentro de UPZ × tipo × trimestre): Alquiler vs. Venta"
) |>
gt::tab_options(table.font.size = "small") |>
gt::tab_source_note(
gt::md(paste0(
"**Notas:** Δ-regresión con pares NN dentro de (UPLCODIGO, tipo, tri_anio). ",
"La interacción captura heterogeneidad por estrato del primer elemento del par. ",
"Errores estándar: HC. Si una columna muestra NA, no hubo pares suficientes."
))
)
gt::gtsave(tbl_diff, filename = file.path(views, "tabla_diferencias_vs_operacion.png"), zoom = 1)
# TABLA 2: FE + CONLEY (Alquiler vs Venta) ----------
mods_conley <- list(
"Venta - FE+Conley"    = m_conley_venta,
"Alquiler - FE+Conley" = m_conley_alquiler
)
attr(mods_conley[[1]], "se.type") <- "Conley"
attr(mods_conley[[2]], "se.type") <- "Conley"
tbl_conley <- modelsummary::msummary(
mods_conley,
output      = "gt",
coef_rename = rename_fun_all,
gof_map     = gmap_common,
stars       = c('*' = .1, '**' = .05, '***' = .01),
title       = "FE + Conley (UPZ, tipo, trimestre-año): Alquiler vs. Venta"
) |>
gt::tab_options(table.font.size = "small") |>
gt::tab_source_note(
gt::md(paste0(
"**Notas:** Especificación: log(Precio) ~ A_parque × estrato + controles | FE(UPLCODIGO, tipo, tri_anio). ",
"Errores Conley con cutoff 50 km (ajustable)."
))
)
gt::gtsave(tbl_conley, filename = file.path(views, "tabla_conley_vs_operacion.png"), zoom = 1)
##########################################################
# Taller 1 - Económia Urbana
# Ejercicio 1
# author: Eimmy Nicoll Tovar Escobar y Juan Sebastian Tellez Melo
##########################################################
# Clean the workspace -----------------------------------------------------
rm(list=ls())
# Definir directorios -----------------------------------------------------
users <- tolower(Sys.info()[["user"]])
rutas <- list(
usuario = "C:/Users/Usuario/OneDrive - RADDAR/Documentos/Documents/Sebastian Tellez/MAESTRIA/ECONOMIA URBANA/TALLER/TALLER 1/Taller_1_EU/",
Eimmy  = "C:/Users/mora/Path/To/TALLER/TALLER 1/"
)
root <- rutas[[users]]
setwd(root)
stores <- file.path(root, "stores")
scripts <- file.path(root, "scripts")
views <- file.path(root, "views")
# Load Packages -----------------------------------------------------------
#install.packages("pacman")
require("pacman")
p_load(
tidyverse,  # Manipulación y visualización de datos
rio,        # Importar/exportar distintos formatos (Excel, Stata, etc.)
skimr,      # resúmenes exploratorios rápidos de data frames
modeldata,  # Datos de ejemplo (incluye Ames Housing)
stargazer,  # Tablas elegantes para resultados econom?tricos
broom,      # Resultados de modelos en dataframes limpios
fixest,     # Estimaciones con efectos fijos y robustas
dplyr,      # Manipulación de datos (incluido en tidyverse, pero lo dejamos explícito)
ggplot2,
stringr,
)
# Cargar datos -----------------------------------------------------------
data_input <- import("stores/dataTaller01_PriceIndeces.rds") %>% as_tibble()
### a) metodología de indice hedónico --------------------------------------------------------
# Inspección inicial del dataframe -----------------------------------------------------------
colnames(data_input)
head(data_input)  # primeras filas
skim(data_input)
table(data_input$year) # frecuencias del año de venta
class(data_input$year)
summary(data_input$sale_price)
# graficas Descriptivas -----------------------------------------------------------
ggplot(data_input, aes(x = sale_price)) +
geom_histogram(bins = 50, col= "white")
# Filtramos datos sin NA en building_sqft, num_bedrooms, num_rooms y num_full_baths ----
data_clean<- data_input %>%
filter(!is.na(building_sqft))
skim(data_clean)
# Transformar el año de venta a factor -----------------------------------------------------------
data_clean <- data_clean %>%
mutate(
year_Sold = factor(
year,
levels = c(2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020),
labels = c("d2000", "d2001", "d2002", "d2003", "d2004", "d2005", "d2006", "d2007", "d2008", "d2009", "d2010", "d2011", "d2012", "d2013", "d2014", "d2015", "d2016", "d2017", "d2018", "d2019", "d2020")
)
)
table(data_clean$year_Sold)
class(data_clean$year_Sold)
# Añadimos el logaritmo del precio de venta -----------------------------------------------------------
data_clean <- data_clean %>%
mutate(log_Sale_Price = log(sale_price))
ggplot(data_clean, aes(x = log_Sale_Price)) +
geom_histogram(bins = 50, col= "white")
# Añadimos el logaritmo del Superficie del edificio -----------------------------------------------------------
summary(data_clean$building_sqft)
data_clean <- data_clean %>%
mutate(log_building_sqft = log(building_sqft))
ggplot(data_clean, aes(x = log_building_sqft)) +
geom_histogram(bins = 50, col= "white")
# Creamos antiguaedad de la casa
summary(data_clean$year_built)
data_clean <- data_clean %>%
mutate(age_years = year - year_built)
summary(data_clean$age_years)
ggplot(data_clean, aes(x = age_years)) +
geom_histogram(bins = 50, col= "white")
# Creamos numero de baños
data_clean <- data_clean %>%
mutate(num_baths = num_full_baths + 0.5*num_half_baths)
summary(data_clean$num_baths)
# Modelo central ---------------------------------------------------------
base_year <- sort(unique(data_clean$year))[1]   # primera categoría como base
reg1 <- feols(log_Sale_Price ~
i(year, ref = base_year) +                   # dummies de año
log_building_sqft +                          # tamaño
num_baths + num_bedrooms +                   # habitabilidad
age_years +                                  # envejecimiento
num_fireplaces + garage_size +               # amenities
central_air +                                # servicios
construction_quality +                       # calidad
ext_wall_material +                          # materiales
site_desirability +                          # sitio
renovation                                   # renovación
| class + type_of_residence + township_code, # Efectos fijos
data = data_clean,
vcov = ~township_code                        # errores clouster
)
summary(reg1)
reg2 <- feols(log_Sale_Price ~
i(year, ref = base_year) +                   # dummies de año
log_building_sqft +                          # tamaño
num_baths + num_bedrooms +                   # habitabilidad
age_years +                                  # envejecimiento
num_fireplaces + garage_size +               # amenities
central_air +                                # servicios
construction_quality +                       # calidad
ext_wall_material +                          # materiales
site_desirability +                          # sitio
renovation                                   # renovación
|class  + township_code,                     # Efectos fijos
data = data_clean,
vcov = "HC1"                                 # errores robustos
)
summary(reg2)
etable(reg1, reg2)
# Desarrollo de índice ---------------------------------------------------------
m <- reg2  # o reg1
# 1) Extraer β_t y Var(β_t) de los dummies year::2001,...,year::2020
yrs <- 2001:2020
nm  <- paste0("year::", yrs)
bet <- coef(m)[nm]                 # β_t (en el orden de nm)
var <- diag(vcov(m))[nm]           # Var(β_t)
# 2) Construir índice con corrección de Goetzmann y IC95% (base = 2000 → β=0, Var=0)
idx_df_A <- tibble(
year  = c(2000, yrs),
beta  = c(0, unname(bet)),
var_b = c(0, unname(var))
) |>
mutate(
se_b      = sqrt(var_b),                     # EE(β_t)
index     = 100 * exp(beta + 0.5 * var_b),   # Goetzmann (1992)
se_index  = index * se_b,                    # Delta method: SE(I) ≈ I·SE(β)
lwr       = index - qnorm(0.975) * se_index, # IC95% inferior
upr       = index + qnorm(0.975) * se_index  # IC95% superior
)
# 3) Gráfica: índice y banda de confianza
ggplot(idx_df_A, aes(year, index)) +
geom_ribbon(aes(ymin = lwr, ymax = upr), alpha = 0.2) +
geom_line(linewidth = 0.9) +
geom_hline(yintercept = 100, linetype = 2) +
labs(title = "Índice hedónico (Goetzmann) con IC 95%",
x = "Año", y = "Índice (base = 100)") +
theme_minimal()
### b) metodolog´ıa de el estimador de ventas repetidas --------------------------------------------------------
# 1) Preparación: pares consecutivos de ventas (s, t) por inmueble ---------------------------------
# Numerar ventas y filtrar inmuebles con 2+ ventas
house_sales <- data_input %>%
arrange(pin, year) %>%
group_by(pin) %>%
mutate(times_sold = row_number()) %>%
filter(n() > 1) %>%                 # solo inmuebles con ventas repetidas
ungroup()
# Construir pares consecutivos: (price0, time0) → (price1, time1)
rep_sales <- house_sales %>%
arrange(pin, year) %>%
group_by(pin) %>%
mutate(price0 = lag(sale_price),
time0  = lag(year)) %>%
ungroup() %>%
filter(!is.na(price0), !is.na(time0)) %>%
transmute(
pin,
price1 = sale_price,  price0 = price0,
time1  = year,   time0  = time0
)
# Variable dependiente: diferencia en log-precios (ΔV_i = lnP_t − lnP_s)
rep_sales <- rep_sales %>%
mutate(dv = log(price1) - log(price0))
# 2) Matriz de diseño D (dummies de tiempo para 2001–2020, base 2000) ---------------
years_all <- 2000:2020
yrs       <- 2001:2020                 # columnas del diseño (base=2000)
n         <- nrow(rep_sales)
# Construir X (n × 20) con la regla {+1, −1, 0}
xmat <- matrix(0, nrow = n, ncol = length(yrs))
for (j in seq_along(yrs)) {
yrj <- yrs[j]
xmat[, j] <- ifelse(rep_sales$time1 == yrj,  1,
ifelse(rep_sales$time0 == yrj, -1, 0))
}
colnames(xmat) <- paste0("Time", yrs)
# 3) Etapa 1 (MCO): ΔV = D·β + ε (sin intercepto) -------------------------------
fit1 <- lm(rep_sales$dv ~ xmat + 0)   # "+ 0" = sin intercepto (base 2000)
summary(fit1)
e1 <- resid(fit1)                      # residuos etapa 1
# 4) Etapa 2 (Varianza): ajustar Var(ε) ≈ A·Δ + B·Δ² + C y construir pesos -----------
delta <- rep_sales$time1 - rep_sales$time0
fit_var <- lm(I(e1^2) ~ delta + I(delta^2))           # Var(ε) = AΔ + BΔ² + C
vhat    <- pmax(fitted(fit_var), 1e-8)                 # asegurar positividad
wgt     <- 1 / vhat
# 5) Etapa 3 (GLS/MCG): ΔV /√v̂ = (D/√v̂)·β + ε/√v̂ → estimación eficiente de β -------------
fit3 <- lm(rep_sales$dv ~ xmat + 0, weights = wgt)
summary(fit3)
# 6) Índice de precios (base 2000) con corrección de Goetzmann + IC95% ------------------
# Extraer β_t y Var(β_t) en el orden de 2001..2020
nm   <- paste0("xmatTime", yrs)                 # nombres de coeficientes en fit3
beta <- coef(fit3)[nm]
vbet <- diag(vcov(fit3))[nm]
# Tibble del índice (agregando el año base 2000 con β=0, Var=0)
idx_df_B <- tibble(
year  = c(2000, yrs),
beta  = c(0, unname(beta)),
vbeta = c(0, unname(vbet))
) %>%
mutate(
se_beta   = sqrt(vbeta),
index     = 100 * exp(beta + 0.5 * vbeta),      # Goetzmann
se_index  = index * se_beta,                    # Delta method
lwr       = index - qnorm(0.975) * se_index,    # IC 95% inferior
upr       = index + qnorm(0.975) * se_index     # IC 95% superior
)
# Gráfica: índice (línea) + banda de IC
ggplot(idx_df_B, aes(x = year, y = index)) +
geom_ribbon(aes(ymin = lwr, ymax = upr), alpha = 0.20) +
geom_line(linewidth = 0.9) +
geom_hline(yintercept = 100, linetype = 2) +
labs(title = "Índice de ventas repetidas (base 2000) — Goetzmann corregido",
x = "Año", y = "Índice (base = 100)") +
theme_minimal()
### c) Estimar FE por propiedad, cluster por id --------------------------------------------------------
# Usamos i(year, ref=2000) para fijar explícitamente el año base
reg_fe <- feols(
log(sale_price) ~ i(year, ref = 2000) | pin,   # FE: id (propiedad)
data = data_input,
vcov = ~ pin                                   # errores agrupados por id
)
etable(reg_fe)
# Extraer betas de año y varianzas (2001–2020)
yrs <- 2001:2020
nm  <- paste0("year::", yrs)               # nombres esperados en feols con i(year)
beta <- coef(reg_fe)[nm]                   # β_t
vbet <- diag(vcov(reg_fe))[nm]             # Var(β_t) con clustering por id
# Índice con corrección de Goetzmann + IC95%
idx_df_C <- tibble(
year  = c(2000, yrs),
beta  = c(0, unname(beta)),              # β_2000 = 0 por construcción
vbeta = c(0, unname(vbet))               # Var_2000 = 0
) %>%
mutate(
se_beta  = sqrt(vbeta),
index    = 100 * exp(beta + 0.5 * vbeta),      # Goetzmann (1992)
se_index = index * se_beta,                     # delta method
lwr      = index - qnorm(0.975) * se_index,     # IC 95% inferior
upr      = index + qnorm(0.975) * se_index      # IC 95% superior
)
#Gráfica del índice con banda de IC
ggplot(idx_df_C, aes(x = year, y = index)) +
geom_ribbon(aes(ymin = lwr, ymax = upr), alpha = 0.20) +
geom_line(linewidth = 0.9) +
geom_hline(yintercept = 100, linetype = 2) +
labs(title = "Índice (FE por propiedad, errores cluster a nivel id)\nBase 2000 — Goetzmann corregido",
x = "Año", y = "Índice (base = 100)") +
theme_minimal()
###  2. Presente los resultados en una grafica --------------------------------------------------------
# 1) Combinar las tres tablas ----------
idx_long <- bind_rows(
idx_df_A %>%
transmute(year, index, lwr, upr, metodo = "Hedónico"),
idx_df_B %>%
transmute(year, index, lwr, upr, metodo = "Ventas repetidas"),
idx_df_C %>%
transmute(year, index, lwr, upr, metodo = "FE por propiedad")
) %>%
mutate(
metodo = factor(metodo, levels = c("Hedónico", "Ventas repetidas", "FE por propiedad"))
)
# 2) Gráfica: tres líneas con sus bandas de confianza (IC 95%)-------
ggplot(idx_long, aes(x = year, y = index, color = metodo)) +
geom_ribbon(aes(ymin = lwr, ymax = upr, fill = metodo), alpha = 0.12, colour = NA) +
geom_line(linewidth = 1) +
geom_hline(yintercept = 100, linetype = 2) +
labs(
title = "Índices de precios: Hedónico vs Ventas repetidas vs FE por propiedad",
subtitle = "Base = 2000, corrección de Goetzmann, IC 95%",
x = "Año", y = "Índice (base = 100)", color = "Método", fill = "Método"
) +
theme_minimal() +
theme(
legend.position = "bottom",
plot.title = element_text(face = "bold")
)
ggplot(idx_long, aes(x = year, y = index, color = metodo)) +
geom_ribbon(aes(ymin = lwr, ymax = upr, fill = metodo), alpha = 0.12, colour = NA) +
geom_line(linewidth = 1) +
geom_hline(yintercept = 100, linetype = 2) +
labs(
title = "Índices de precios: Hedónico vs Ventas repetidas vs FE por propiedad",
subtitle = "Base = 2000, corrección de Goetzmann, IC 95%",
x = "Año", y = "Índice (base = 100)", color = "Método", fill = "Método"
) +
theme_minimal() +
theme(
legend.position = "bottom",
plot.title = element_text(face = "bold")
)
